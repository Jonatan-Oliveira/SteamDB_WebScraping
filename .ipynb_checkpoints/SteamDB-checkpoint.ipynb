{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416e0e27",
   "metadata": {},
   "source": [
    "# STEAMDB - SALES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaec1e9",
   "metadata": {},
   "source": [
    "## WEBSCRAPING + CSV para o Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40984e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from google.cloud import bigquery\n",
    "\n",
    "#caminho do Arquivo baixado na minha maquina\n",
    "file_path = r'C:\\Users\\Notbook I3\\Downloads\\Steam Summer Sale 2023 · BR · SteamDB.html'\n",
    "\n",
    "# Lê o arquivo HTML\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Faz o parsing do conteúdo HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Cria uma lista vazia para armazenar os dados\n",
    "data = []\n",
    "\n",
    "# Itera sobre cada linha da tabela HTML\n",
    "for row in soup.find_all('tr'):\n",
    "    # Encontra os campos name, discount, price, rating e ends_in\n",
    "    name = row.find('a', class_='b')\n",
    "    discount = row.find('td', class_='price-discount-major')\n",
    "    price = None\n",
    "    for td in row.find_all('td'):\n",
    "        if td.text.strip().startswith('R$'):\n",
    "            price = td.text.strip()\n",
    "            break\n",
    "    rating = row.find('td', {'data-sort': lambda x: x is not None and '.' in x})\n",
    "    ends_in = row.find('td', class_='timeago')\n",
    "\n",
    "    # Encontra os campos started e release com base no campo ends_in\n",
    "    if ends_in:\n",
    "        started = ends_in.find_next_sibling('td', class_='timeago')\n",
    "        if started:\n",
    "            release = started.find_next_sibling('td', {'data-sort': True})\n",
    "        else:\n",
    "            release = None\n",
    "    else:\n",
    "        started = None\n",
    "        release = None\n",
    "\n",
    "    # Verifica se todos os campos necessários estão presentes\n",
    "    if name and discount and price and rating and ends_in:\n",
    "        # Extrai o texto de cada campo e armazena em variáveis\n",
    "        name_text = name.text.strip() if name.text else ''\n",
    "        discount_text = discount.text.strip() if discount.text else ''\n",
    "        price_text = price\n",
    "        rating_text = rating.text.strip() if rating.text else ''\n",
    "        ends_in_text = ends_in.text.strip() if ends_in.text else ''\n",
    "        started_text = started.text.strip() if started and started.text else ''\n",
    "        release_text = release.text.strip() if release and release.text else ''\n",
    "\n",
    "        # Adiciona os dados como um dicionário à lista\n",
    "        data.append({\n",
    "            'Name': name_text,\n",
    "            '%': discount_text,\n",
    "            'Price': price_text,\n",
    "            'Rating': rating_text,\n",
    "            'Ends in': ends_in_text,\n",
    "            'Started': started_text,\n",
    "            'Release': release_text\n",
    "        })\n",
    "\n",
    "# Cria um DataFrame usando os dados coletados\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Salva o DataFrame em um arquivo CSV\n",
    "csv_file_path = 'dados_steam_sale.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Configura o cliente do BigQuery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define os detalhes da tabela do BigQuery\n",
    "pproject_id = 'steamdb-beanalitics'\n",
    "dataset_id = 'steamdb_sales'\n",
    "table_name = 'steamdb_sales'\n",
    "\n",
    "# Define o esquema da tabela do BigQuery\n",
    "schema = [\n",
    "    bigquery.SchemaField('Name', 'STRING'),\n",
    "    bigquery.SchemaField('%', 'STRING'),\n",
    "    bigquery.SchemaField('Price', 'STRING'),\n",
    "    bigquery.SchemaField('Rating', 'STRING'),\n",
    "    bigquery.SchemaField('Ends in', 'STRING'),\n",
    "    bigquery.SchemaField('Started', 'STRING'),\n",
    "    bigquery.SchemaField('Release', 'STRING')\n",
    "]\n",
    "\n",
    "# Carrega o arquivo CSV para a tabela do BigQuery\n",
    "dataset_ref = client.dataset(dataset_id, project=project_id)\n",
    "table_ref = dataset_ref.table(table_name)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(schema=schema, source_format=bigquery.SourceFormat.CSV)\n",
    "with open(csv_file_path, 'rb') as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Aguarda a conclusão do job\n",
    "\n",
    "# Imprime a confirmação\n",
    "print('Dados carregados na tabela do BigQuery:', table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c08d4e",
   "metadata": {},
   "source": [
    "## ENVIAR DO BIG_QUERY PARA GOOGLE SHEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gspread\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Configuração do projeto do BigQuery\n",
    "project_id = 'steamdb-beanalitics'\n",
    "dataset_id = 'steamdb_sales'\n",
    "table_name = 'steamdb_sales'\n",
    "\n",
    "# Configuração do cliente BigQuery\n",
    "client_bq = bigquery.Client(project=project_id)\n",
    "table_ref = client_bq.dataset(dataset_id).table(table_name)\n",
    "\n",
    "# Executa uma consulta e obtém os resultados\n",
    "query = f\"SELECT * FROM `{project_id}.{dataset_id}.{table_name}`\"\n",
    "query_job = client_bq.query(query)\n",
    "results = query_job.result()\n",
    "\n",
    "# Converte os resultados em um DataFrame do pandas\n",
    "df = pd.DataFrame(results.to_dataframe())\n",
    "\n",
    "# Configuração do projeto do Google Sheets\n",
    "credentials_file = 'steamdb-beanalitics-22915f5de0a0.json'\n",
    "spreadsheet_id = '1ulcB7BD5VQXL4eGpyp2X9eZWwK8ltW_oRy4p-I0-AyU'\n",
    "\n",
    "# Configuração das credenciais do Google Sheets\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_file)\n",
    "credentials = credentials.with_scopes(['https://www.googleapis.com/auth/spreadsheets'])\n",
    "\n",
    "client_sheets = gspread.authorize(credentials)\n",
    "\n",
    "# Abre a planilha do Google Sheets\n",
    "spreadsheet = client_sheets.open_by_key(spreadsheet_id)\n",
    "\n",
    "# Seleciona a primeira aba da planilha\n",
    "worksheet = spreadsheet.get_worksheet(0)\n",
    "\n",
    "# Limpa os dados existentes na planilha\n",
    "worksheet.clear()\n",
    "\n",
    "# Converte o DataFrame para uma lista de listas\n",
    "values = df.values.tolist()\n",
    "\n",
    "# Insere os novos dados na planilha\n",
    "worksheet.update(values)\n",
    "\n",
    "print('Dados enviados com sucesso para o Google Sheets!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5bcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6de44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f14844ff",
   "metadata": {},
   "source": [
    "# codigo 1 OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964741ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados na tabela do BigQuery: steamdb_sales\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def parse_html(file_path):\n",
    "    # Lê o arquivo HTML\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Faz o parsing do conteúdo HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    return soup\n",
    "\n",
    "def extract_data(soup):\n",
    "    # Cria uma lista vazia para armazenar os dados\n",
    "    data = []\n",
    "\n",
    "    # Itera sobre cada linha da tabela HTML\n",
    "    for row in soup.find_all('tr'):\n",
    "        # Encontra os campos name, discount, price, rating e ends_in\n",
    "        name = row.find('a', class_='b')\n",
    "        discount = row.find('td', class_='price-discount-major')\n",
    "        price = None\n",
    "        for td in row.find_all('td'):\n",
    "            if td.text.strip().startswith('R$'):\n",
    "                price = td.text.strip()\n",
    "                break\n",
    "        rating = row.find('td', {'data-sort': lambda x: x is not None and '.' in x})\n",
    "        ends_in = row.find('td', class_='timeago')\n",
    "\n",
    "        # Encontra os campos started e release com base no campo ends_in\n",
    "        if ends_in:\n",
    "            started = ends_in.find_next_sibling('td', class_='timeago')\n",
    "            if started:\n",
    "                release = started.find_next_sibling('td', {'data-sort': True})\n",
    "            else:\n",
    "                release = None\n",
    "        else:\n",
    "            started = None\n",
    "            release = None\n",
    "\n",
    "        # Verifica se todos os campos necessários estão presentes\n",
    "        if name and discount and price and rating and ends_in:\n",
    "            # Extrai o texto de cada campo e armazena em variáveis\n",
    "            name_text = name.text.strip() if name.text else ''\n",
    "            discount_text = discount.text.strip() if discount.text else ''\n",
    "            price_text = price\n",
    "            rating_text = rating.text.strip() if rating.text else ''\n",
    "            ends_in_text = ends_in.text.strip() if ends_in.text else ''\n",
    "            started_text = started.text.strip() if started and started.text else ''\n",
    "            release_text = release.text.strip() if release and release.text else ''\n",
    "\n",
    "            # Adiciona os dados como um dicionário à lista\n",
    "            data.append({\n",
    "                'Name': name_text,\n",
    "                '%': discount_text,\n",
    "                'Price': price_text,\n",
    "                'Rating': rating_text,\n",
    "                'Ends in': ends_in_text,\n",
    "                'Started': started_text,\n",
    "                'Release': release_text\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_to_csv(data, csv_file_path):\n",
    "    # Cria um DataFrame usando os dados coletados\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Salva o DataFrame em um arquivo CSV\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "def load_to_bigquery(csv_file_path, project_id, dataset_id, table_name):\n",
    "    # Configura o cliente do BigQuery\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Define os detalhes da tabela do BigQuery\n",
    "    dataset_ref = client.dataset(dataset_id, project=project_id)\n",
    "    table_ref = dataset_ref.table(table_name)\n",
    "\n",
    "    # Define o esquema da tabela do BigQuery\n",
    "    schema = [\n",
    "        bigquery.SchemaField('Name', 'STRING'),\n",
    "        bigquery.SchemaField('%', 'STRING'),\n",
    "        bigquery.SchemaField('Price', 'STRING'),\n",
    "        bigquery.SchemaField('Rating', 'STRING'),\n",
    "        bigquery.SchemaField('Ends in', 'STRING'),\n",
    "        bigquery.SchemaField('Started', 'STRING'),\n",
    "        bigquery.SchemaField('Release', 'STRING')\n",
    "    ]\n",
    "\n",
    "    # Carrega o arquivo CSV para a tabela do BigQuery\n",
    "    job_config = bigquery.LoadJobConfig(schema=schema, source_format=bigquery.SourceFormat.CSV)\n",
    "    with open(csv_file_path, 'rb') as source_file:\n",
    "        job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "    job.result()  # Aguarda a conclusão do job\n",
    "\n",
    "    # Imprime a confirmação\n",
    "    print('Dados carregados na tabela do BigQuery:', table_name)\n",
    "\n",
    "# Caminho do arquivo baixado na minha máquina\n",
    "file_path = r'C:\\Users\\Notbook I3\\Downloads\\Steam Summer Sale 2023 · BR · SteamDB.html'\n",
    "\n",
    "# Parse do HTML\n",
    "soup = parse_html(file_path)\n",
    "\n",
    "# Extrair dados\n",
    "data = extract_data(soup)\n",
    "\n",
    "# Caminho do arquivo CSV para salvar os dados\n",
    "csv_file_path = 'dados_steam_sale.csv'\n",
    "\n",
    "# Salvar dados em CSV\n",
    "save_to_csv(data, csv_file_path)\n",
    "\n",
    "# Configuração do BigQuery\n",
    "project_id = 'steamdb-beanalitics'\n",
    "dataset_id = 'steamdb_sales'\n",
    "table_name = 'steamdb_sales'\n",
    "\n",
    "# Carregar dados para o BigQuery\n",
    "load_to_bigquery(csv_file_path, project_id, dataset_id, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8a10d",
   "metadata": {},
   "source": [
    "# OTIMIZANDO O CODIGO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0cb7e0",
   "metadata": {},
   "source": [
    "# codigo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ee8b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Notbook I3\\.conda\\lib\\site-packages\\gspread\\worksheet.py:1046: UserWarning: [Deprecated][in version 6.0.0]: method signature will change to: 'Worksheet.update(value = [[]], range_name=)' arguments 'range_name' and 'values' will swap, values will be mandatory of type: 'list(list(...))'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados enviados com sucesso para o Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gspread\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def run_bigquery_query(project_id, dataset_id, table_name):\n",
    "    # Configuração do cliente BigQuery\n",
    "    client_bq = bigquery.Client(project=project_id)\n",
    "    table_ref = client_bq.dataset(dataset_id).table(table_name)\n",
    "\n",
    "    # Executa uma consulta e obtém os resultados\n",
    "    query = f\"SELECT * FROM `{project_id}.{dataset_id}.{table_name}`\"\n",
    "    query_job = client_bq.query(query)\n",
    "    results = query_job.result()\n",
    "\n",
    "    # Converte os resultados em um DataFrame do pandas\n",
    "    df = pd.DataFrame(results.to_dataframe())\n",
    "\n",
    "    return df\n",
    "\n",
    "def upload_dataframe_to_google_sheets(df, credentials_file, spreadsheet_id, sheet_index=0):\n",
    "    # Configuração das credenciais do Google Sheets\n",
    "    credentials = service_account.Credentials.from_service_account_file(credentials_file)\n",
    "    credentials = credentials.with_scopes(['https://www.googleapis.com/auth/spreadsheets'])\n",
    "\n",
    "    client_sheets = gspread.authorize(credentials)\n",
    "\n",
    "    # Abre a planilha do Google Sheets\n",
    "    spreadsheet = client_sheets.open_by_key(spreadsheet_id)\n",
    "\n",
    "    # Seleciona a aba da planilha\n",
    "    worksheet = spreadsheet.get_worksheet(sheet_index)\n",
    "\n",
    "    # Limpa os dados existentes na planilha\n",
    "    worksheet.clear()\n",
    "\n",
    "    # Converte o DataFrame para uma lista de listas\n",
    "    values = df.values.tolist()\n",
    "\n",
    "    # Insere os novos dados na planilha\n",
    "    worksheet.update(values)\n",
    "\n",
    "    print('Dados enviados com sucesso para o Google Sheets!')\n",
    "\n",
    "# Configuração do projeto do BigQuery\n",
    "project_id = 'steamdb-beanalitics'\n",
    "dataset_id = 'steamdb_sales'\n",
    "table_name = 'steamdb_sales'\n",
    "\n",
    "# Configuração do projeto do Google Sheets\n",
    "credentials_file = 'steamdb-beanalitics-22915f5de0a0.json'\n",
    "spreadsheet_id = '1ulcB7BD5VQXL4eGpyp2X9eZWwK8ltW_oRy4p-I0-AyU'\n",
    "\n",
    "# Executa a consulta no BigQuery e obtém os resultados como DataFrame\n",
    "df = run_bigquery_query(project_id, dataset_id, table_name)\n",
    "\n",
    "# Envia o DataFrame para o Google Sheets\n",
    "upload_dataframe_to_google_sheets(df, credentials_file, spreadsheet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ea96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
